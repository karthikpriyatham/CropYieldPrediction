{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c2da366",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import PyPDF2\n",
    "import textract\n",
    "import pdfplumber\n",
    "import base64\n",
    "import re\n",
    "import io\n",
    "import os\n",
    "import pdfid\n",
    "import csv\n",
    "from collections import Counter\n",
    "from os import path\n",
    "from glob import glob  \n",
    "from itertools import chain\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score, auc\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn import svm\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f31e829b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column names are State_Name, District_Name, Crop_Year, Season, Crop, Area, Production\n",
      "Processed 242362 lines.\n",
      "(242361, 6)\n"
     ]
    }
   ],
   "source": [
    "# Read a CSV File into a list \n",
    "csvRawData = []\n",
    "\n",
    "StateDict = {}\n",
    "StateInvDict = {}\n",
    "StateCount = 0\n",
    "\n",
    "DistrictDict = {}\n",
    "DistrictInvDict = {}\n",
    "DistrictCount = 0\n",
    "\n",
    "CropYearDict = {}\n",
    "CropYearInvDict = {}\n",
    "CropYearCount = 0\n",
    "\n",
    "CropSeasonDict = {}\n",
    "CropSeasonInvDict = {}\n",
    "SeasonCount = 0\n",
    "\n",
    "CropTypeDict = {}\n",
    "CropTypeInvDict = {}\n",
    "CropTypeCount = 0\n",
    "\n",
    "DataList  = []\n",
    "LabelList = []\n",
    "\n",
    "ignore_zero_rows = True\n",
    "\n",
    "with open('crop_production.csv') as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "    line_count = 0\n",
    "    \n",
    "    LabelList = []\n",
    "    for row in csv_reader:\n",
    "        if line_count == 0:\n",
    "            print(f'Column names are {\", \".join(row)}')\n",
    "        else:\n",
    "            \n",
    "            if ignore_zero_rows == True and row[6] == '':\n",
    "                 continue\n",
    "                    \n",
    "            sub_input_row = []\n",
    "            \n",
    "            if row[0] not in StateDict :\n",
    "                StateDict[row[0]] = StateCount\n",
    "                StateCount = StateCount + 1\n",
    "            sub_input_row.append(StateDict[row[0]])\n",
    "            \n",
    "            if row[1] not in DistrictDict :\n",
    "                DistrictDict[row[1]] = DistrictCount\n",
    "                DistrictCount = DistrictCount + 1\n",
    "            sub_input_row.append(DistrictDict[row[1]])\n",
    "            \n",
    "            if row[2] not in CropYearDict :\n",
    "                CropYearDict[row[2]] = CropYearCount\n",
    "                CropYearCount = CropYearCount + 1\n",
    "            sub_input_row.append(CropYearDict[row[2]])\n",
    "            \n",
    "            if row[3] not in CropSeasonDict :\n",
    "                CropSeasonDict[row[3]] = SeasonCount\n",
    "                SeasonCount = SeasonCount + 1      \n",
    "            sub_input_row.append(CropSeasonDict[row[3]])\n",
    "            \n",
    "            if row[4] not in CropTypeDict :\n",
    "                CropTypeDict[row[4]] = CropTypeCount\n",
    "                CropTypeCount = CropTypeCount + 1      \n",
    "            sub_input_row.append(CropTypeDict[row[4]])\n",
    "            \n",
    "            sub_input_row.append(float(row[5]))\n",
    "            \n",
    "            if row[6] == '' :\n",
    "                LabelList.append(float(0))\n",
    "            else : \n",
    "                LabelList.append(float(row[6]))\n",
    "                \n",
    "            DataList.append(sub_input_row)\n",
    "        line_count += 1\n",
    "        \n",
    "    print(f'Processed {line_count} lines.')\n",
    "    \n",
    "\n",
    "cut = len(LabelList)\n",
    "#cut = 100000\n",
    "\n",
    "DataSet = np.array(DataList[:cut][:])\n",
    "Labels = np.array(LabelList[:cut])\n",
    "\n",
    "print(DataSet.shape)\n",
    "\n",
    "#Get IVDicts for all the existing Dictionaries\n",
    "StateInvDict = dict((v, k) for k, v in StateDict.items())\n",
    "DistrictInvDict = dict((v, k) for k, v in DistrictDict.items())\n",
    "CropYearInvDict = dict((v, k) for k, v in CropYearDict.items())\n",
    "CropSeasonInvDict = dict((v, k) for k, v in CropSeasonDict.items())\n",
    "CropTypeInvDict = dict((v, k) for k, v in CropTypeDict.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b48f0f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State_Name</th>\n",
       "      <th>District_Name</th>\n",
       "      <th>Crop_Year</th>\n",
       "      <th>Season</th>\n",
       "      <th>Crop</th>\n",
       "      <th>Area</th>\n",
       "      <th>Production</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Andaman and Nicobar Islands</td>\n",
       "      <td>NICOBARS</td>\n",
       "      <td>2000</td>\n",
       "      <td>Kharif</td>\n",
       "      <td>Arecanut</td>\n",
       "      <td>1254.0</td>\n",
       "      <td>2000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Andaman and Nicobar Islands</td>\n",
       "      <td>NICOBARS</td>\n",
       "      <td>2000</td>\n",
       "      <td>Kharif</td>\n",
       "      <td>Other Kharif pulses</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Andaman and Nicobar Islands</td>\n",
       "      <td>NICOBARS</td>\n",
       "      <td>2000</td>\n",
       "      <td>Kharif</td>\n",
       "      <td>Rice</td>\n",
       "      <td>102.0</td>\n",
       "      <td>321.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Andaman and Nicobar Islands</td>\n",
       "      <td>NICOBARS</td>\n",
       "      <td>2000</td>\n",
       "      <td>Whole Year</td>\n",
       "      <td>Banana</td>\n",
       "      <td>176.0</td>\n",
       "      <td>641.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Andaman and Nicobar Islands</td>\n",
       "      <td>NICOBARS</td>\n",
       "      <td>2000</td>\n",
       "      <td>Whole Year</td>\n",
       "      <td>Cashewnut</td>\n",
       "      <td>720.0</td>\n",
       "      <td>165.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    State_Name District_Name Crop_Year       Season  \\\n",
       "0  Andaman and Nicobar Islands      NICOBARS      2000  Kharif        \n",
       "1  Andaman and Nicobar Islands      NICOBARS      2000  Kharif        \n",
       "2  Andaman and Nicobar Islands      NICOBARS      2000  Kharif        \n",
       "3  Andaman and Nicobar Islands      NICOBARS      2000  Whole Year    \n",
       "4  Andaman and Nicobar Islands      NICOBARS      2000  Whole Year    \n",
       "\n",
       "                  Crop    Area  Production  \n",
       "0             Arecanut  1254.0      2000.0  \n",
       "1  Other Kharif pulses     2.0         1.0  \n",
       "2                 Rice   102.0       321.0  \n",
       "3               Banana   176.0       641.0  \n",
       "4            Cashewnut   720.0       165.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def DictionaryIterator( Dict, List) :\n",
    "    print(List)\n",
    "    return \n",
    "\n",
    "DFRaw = pd.DataFrame({'State_Name': DataSet[:, 0], 'District_Name': DataSet[:, 1], 'Crop_Year':DataSet[:,2], 'Season':DataSet[:,3], 'Crop':DataSet[:,4], 'Area': DataSet[:,5], 'Production':Labels[:]}) \n",
    "DFRaw.head()\n",
    "\n",
    "DF = pd.DataFrame({'State_Name': [StateInvDict[row] for row in DataSet[:, 0]] , 'District_Name': [DistrictInvDict[row] for row in DataSet[:, 1]], 'Crop_Year':[CropYearInvDict[row] for row in DataSet[:, 2]], 'Season':[CropSeasonInvDict[row] for row in DataSet[:, 3]], 'Crop':[CropTypeInvDict[row] for row in DataSet[:, 4]], 'Area': DataSet[:,5], 'Production':Labels[:]}) \n",
    "DF.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2abde2ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Crop_Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Plums</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jowar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dry ginger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Peach</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pump Kin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>Citrus Fruit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>Khesari</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>Cashewnut Processed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>Other Fresh Fruits</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>Other Kharif pulses</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>124 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Crop_Type\n",
       "0                  Plums\n",
       "1                  Jowar\n",
       "2             Dry ginger\n",
       "3                  Peach\n",
       "4               Pump Kin\n",
       "..                   ...\n",
       "119         Citrus Fruit\n",
       "120              Khesari\n",
       "121  Cashewnut Processed\n",
       "122   Other Fresh Fruits\n",
       "123  Other Kharif pulses\n",
       "\n",
       "[124 rows x 1 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DF = pd.DataFrame({'Crop_Type': list(set([CropTypeInvDict[row] for row in DataSet[:, 4]]))})\n",
    "DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3776f96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaleData(scaler, dataSet):\n",
    "    DataSet_Scaled = scaler.fit_transform(dataSet)\n",
    "    return DataSet_Scaled\n",
    "\n",
    "def model_train(model) :\n",
    "        model_name = model.__class__.__name__\n",
    "        fit=model.fit(X_trainScaled, y_trainScaled)\n",
    "        y_pred=fit.predict(X_testScaled)\n",
    "        r2=r2_score(y_testScaled, y_pred)\n",
    "        model_train.append([model, model_name, r2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb1f86cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read about MinMaxScaler and Standard Scaler\n",
    "Scalers =[\n",
    "    MinMaxScaler(),\n",
    "    StandardScaler()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ba0d1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Understand the working mechanism of different models\n",
    "models = [\n",
    "    #svm.SVR(),\n",
    "    LinearRegression(),\n",
    "    DecisionTreeRegressor(),\n",
    "    GradientBoostingRegressor(n_estimators=200, random_state=0),\n",
    "    RandomForestRegressor(n_estimators=200, random_state=0) ,\n",
    "    #MLPRegressor(hidden_layer_sizes=(32,16,8),activation=\"tanh\" ,random_state=1, max_iter=100)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae58301",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;New Test Size;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n",
      ";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n",
      ";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n",
      ";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n",
      ";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\n",
      "Test Size Used is :  0.33\n",
      "#######################################################################################################\n",
      "#######################################################################################################\n",
      "\n",
      "\n",
      "Scaler Used is  MinMaxScaler()\n",
      "____________________________________________________________________________________________________\n",
      "Models Trained With Scores are as follows:\n",
      "\n",
      "[LinearRegression(), 'LinearRegression', 0.0023446292215733022]\n",
      "[DecisionTreeRegressor(), 'DecisionTreeRegressor', 0.8997434120988999]\n",
      "[GradientBoostingRegressor(n_estimators=200, random_state=0), 'GradientBoostingRegressor', 0.8296499677326317]\n",
      "[RandomForestRegressor(n_estimators=200, random_state=0), 'RandomForestRegressor', 0.919623658763463]\n",
      "\n",
      "\n",
      "Default Decision Tree Depth with Scaler and setting  MinMaxScaler()  is  43\n",
      "\n",
      "\n",
      "Default GradientBoostingRegressor Tree Depth with Scaler and setting  MinMaxScaler()  is  3\n",
      "\n",
      "\n",
      "Default RandomForestRegressor Tree Depth with Scaler and setting  MinMaxScaler()  is  48\n"
     ]
    }
   ],
   "source": [
    "for testSize in [0.33, 0.3, 0.25, 0.2] :\n",
    "    \n",
    "    print(\";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;New Test Size;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\")\n",
    "    print(\";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\")\n",
    "    print(\";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\")\n",
    "    print(\";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\")\n",
    "    print(\";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;\")\n",
    "    \n",
    "    print(\"Test Size Used is : \", testSize)\n",
    "    for scale in Scalers:\n",
    "        print(\"#######################################################################################################\")\n",
    "        print(\"#######################################################################################################\")\n",
    "\n",
    "        print(\"\\n\\nScaler Used is \", scale)\n",
    "        scaleName = scale.__class__.__name__\n",
    "        DataSetScaled = scaleData(scale, DataSet)\n",
    "        LabelsScaled = Labels\n",
    "\n",
    "        for useScaleForLabels in [0,1]:\n",
    "\n",
    "            print(\"____________________________________________________________________________________________________\")\n",
    "            if(useScaleForLabels == 1):\n",
    "                print(\"Using Scaling for Labels as well\\n\")\n",
    "                LabelsScaled = scaleData(scale, Labels.reshape(-1,1))\n",
    "\n",
    "            X_trainScaled, X_testScaled, y_trainScaled, y_testScaled = train_test_split(DataSetScaled, LabelsScaled, test_size = testSize)\n",
    "            model_train = []\n",
    "\n",
    "            for model in models :\n",
    "                model_name = model.__class__.__name__\n",
    "                fit=model.fit(X_trainScaled, y_trainScaled)\n",
    "                y_pred=fit.predict(X_testScaled)\n",
    "\n",
    "                r2=r2_score(y_testScaled, y_pred)\n",
    "                model_train.append([model, model_name, r2])\n",
    "\n",
    "            print(\"Models Trained With Scores are as follows:\\n\")\n",
    "            print(*model_train, sep = \"\\n\")\n",
    "\n",
    "            # Now test all possible depths with decision tree regressor, Gradient Boosing Regressor, Random Forest Regressor\n",
    "            print(\"\\n\\nDefault Decision Tree Depth with Scaler and setting \", scale, \" is \", model_train[1][0].tree_.max_depth)\n",
    "            print(\"\\n\\nDefault GradientBoostingRegressor Tree Depth with Scaler and setting \", scale, \" is \", max(estimator.tree_.max_depth for estimator in chain.from_iterable(zip(*model_train[2][0].estimators_))))\n",
    "            print(\"\\n\\nDefault RandomForestRegressor Tree Depth with Scaler and setting \", scale, \" is \", max([estimator.get_depth() for estimator in model_train[3][0].estimators_]))\n",
    "            \n",
    "            TreeModelNames = [\"\", \"\", \"\"]\n",
    "            max_Scores = [float(0), float(0), float(0)]\n",
    "            max_ScoreDepths = [int(1), int(1), int(1)]\n",
    "            \n",
    "            for depth in range(1,100):\n",
    "                \n",
    "                TreeModels = [\n",
    "                    DecisionTreeRegressor(max_depth= depth),\n",
    "                    GradientBoostingRegressor(n_estimators=200, max_depth = depth, random_state=0),\n",
    "                    RandomForestRegressor(n_estimators=200, max_depth = depth, random_state=0) \n",
    "                ]\n",
    "                \n",
    "                counter  = int(0)\n",
    "                for model in TreeModels:\n",
    "                    \n",
    "                    model_name = model.__class__.__name__\n",
    "                    fit = model.fit(X_trainScaled, y_trainScaled)\n",
    "                    y_pred=fit.predict(X_testScaled)\n",
    "                    r2=r2_score(y_testScaled, y_pred)\n",
    "\n",
    "                    if(r2 > max_Scores[counter]):\n",
    "                        max_Scores[counter] = r2\n",
    "                        max_ScoreDepths[counter] = depth\n",
    "                    \n",
    "                    TreeModelNames[counter] = model_name\n",
    "                    counter = counter + 1\n",
    "    \n",
    "            for counter in [0,1,2]:\n",
    "                print(\"For Model \", TreeModelNames[counter] ,\" and at Depth \", max_ScoreDepths[counter] , \"Max score of \", max_Scores[counter], \" is obtained\")\n",
    "            print(\"____________________________________________________________________________________________________\")\n",
    "\n",
    "            \n",
    "            \n",
    "        print(\"#######################################################################################################\")\n",
    "        print(\"#######################################################################################################\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6efe689d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
